{
    "version": "https://jsonfeed.org/version/1",
    "title": "Sidey",
    "home_page_url": "http://0.0.0.0:8701/",
    "feed_url": "http://0.0.0.0:8701/feed.json",
    "description": "Simple and minimalistic jekyll blogging theme.",
    "icon": "http://0.0.0.0:8701/apple-touch-icon.png",
    "favicon": "http://0.0.0.0:8701/favicon.ico",
    "expired": false,
    
    "author": "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}",
    
"items": [
    
        {
            "id": "http://0.0.0.0:8701/2023/01/01/tax-optimized-asset-management",
            "title": "",
            "summary": null,
            "content_text": "  일반적인 포트폴리오를 통해 자산관리 및 수익을 얻으려고 할때, 종목의 수익률을 최대화 하려고 한다.      하지만 금융 상품에 대해서 손익통산 및 이월공제가 가능하다면, 보유 포트폴리오 종목의 주가하락에 따른 손실을 기회로 포착하여 Loss를 실현함으로써  절세효과를 극대화하는 전략이 사용 가능해진다.이를 Tax-loss harvesting(TLH)라고 부르고, 포트폴리오 수익률 증대전략이 아닌 절세효과로 인해 알파수익을 추구하는 전략이다.    TLH는 취득원가 미만으로 떨어진 주식을 매도하여 손실을 확정하고 이익실현 가능한 주식 을 동시에 매도하여  납부세금을 절약하는 매매전략 (loss,gain 상쇄)본 프로젝트는 주식 및 ETF의 포트폴리오샘플 알고리즘기술적 분석  PPO  LSTM  Deep Q-Learning강화학습의 리턴은 다음과 같이 설계하였다.\\[return = 10\\]Supervised learning loss design@@ loss 디자인Reinforcement Learning Return designstate action reward@@ loss 디자인위와 같은 결과가 있지만, 실제 서비스에 적용하기는 어렵다는 결론을 내렸다. 그 이유는 사용자 입장에서 Black box 모델의 시뮬레이션 결과를 근거로 모델에 기반한 투자를 선택하기 쉽지 않기 때문이다.  따라서 매우 단순한 loss-cut 전략의 파라미터를 최적화 하는데 ML모델을 사용해 보았다.먼저 다음의 전제들을 가정했다.  주식 트랜드나 가격 예측은 불가능하다.  주식 트랜드나 가격 예측은 어느정도는 가능하다.1번의 경우 ML모델로 특정 패턴에 최적화된 loss-cut 파라미터를 찾아낼 수 가 없다. 따라서 랜덤 확률 프로세스를 사용하여,2번의 경우는 reward#설계 근거## Why design $\\text{Action Space} = { Buy,Sell }$?일반적인 트레이딩이 아닌, tax 최적화를 위해, 이익실현 연기, 손해 확정 등의 액션도 가능하다. 하지만 간단하게 하기 위해 임의로  action space를 단순화 시켰다.Why only single asset?각 주가의 트랜드에 맞게 따라서 최적의 전략을 추천해주는 상위 모델이 따로 있다. 따라서 본 프로젝트에서는 많이 보이는 패턴의 종목에 최적화된 모델을 만드는 것이 우선적인 목표이다. 그리고 종목에 최적화된 모델이 완성 되면, 각 모델의 output을 reward로 하는 종목 추천 모델 훈련에 사용한다.#TLH 평가 방법\\(Value_{TLH} = min(G,L)(\\tau_{t_1} - \\tau_{t_2} + )\\)#Conclusion기존 기술적 분석 기반의 방법론들은 높은 수익률 생기는 주가의 패턴이 확실했다.Machine Learning의 학습 기반 모델의 경우는 많은 주가 패턴 및 트랜드에서 기술적 분석 기반의 방법론들 보다는 수익률의 편차가 작았다.@@ 상승, 박스, 하락 각각의 경우에 대한 기술적 분석 기반 방법 vs RL기반 , LSTM 기반 넣기특히 Deep Learning 기반의 경우는 전처리가 중요하게 보인다.@@ 스무딩 전 후 차이 예시2. RL 기반2. Return 모델링3. 시뮬레이션 결과3. RNN 기반4. FLSTM  전통적인 방법 vs RL  종목에 따른 최적 방법론이 다르다.  종목 구성 후  확률 과정 vs ML Base          Shift      ** 어떻게 no-free lnuch",
            "content_html": "<ul>  <li>일반적인 포트폴리오를 통해 자산관리 및 수익을 얻으려고 할때, 종목의 수익률을 최대화 하려고 한다.</li>  <li>    <p>하지만 금융 상품에 대해서 손익통산 및 이월공제가 가능하다면, 보유 포트폴리오 종목의 주가하락에 따른 손실을 기회로 포착하여 Loss를 실현함으로써  절세효과를 극대화하는 전략이 사용 가능해진다.<br />이를 Tax-loss harvesting(TLH)라고 부르고, 포트폴리오 수익률 증대전략이 아닌 절세효과로 인해 알파수익을 추구하는 전략이다.</p>  </li>  <li>TLH는 취득원가 미만으로 떨어진 주식을 매도하여 손실을 확정하고 이익실현 가능한 주식 을 동시에 매도하여  납부세금을 절약하는 매매전략 (loss,gain 상쇄)</li></ul><p>본 프로젝트는 주식 및 ETF의 포트폴리오</p><p>샘플 알고리즘</p><p>기술적 분석</p><ul>  <li>PPO</li>  <li>LSTM</li>  <li>Deep Q-Learning</li></ul><p>강화학습의 리턴은 다음과 같이 설계하였다.</p>\\[return = 10\\]<p>Supervised learning loss design</p><p>@@ loss 디자인</p><p>Reinforcement Learning Return design</p><p>state action reward</p><p>@@ loss 디자인</p><p>위와 같은 결과가 있지만, 실제 서비스에 적용하기는 어렵다는 결론을 내렸다. 그 이유는 사용자 입장에서 Black box 모델의 시뮬레이션 결과를 근거로 모델에 기반한 투자를 선택하기 쉽지 않기 때문이다.  따라서 매우 단순한 loss-cut 전략의 파라미터를 최적화 하는데 ML모델을 사용해 보았다.</p><p>먼저 다음의 전제들을 가정했다.</p><ol>  <li>주식 트랜드나 가격 예측은 불가능하다.</li>  <li>주식 트랜드나 가격 예측은 어느정도는 가능하다.</li></ol><p>1번의 경우 ML모델로 특정 패턴에 최적화된 loss-cut 파라미터를 찾아낼 수 가 없다. 따라서 랜덤 확률 프로세스를 사용하여,</p><p>2번의 경우는 reward</p><h2 id=\"설계-근거\">#설계 근거</h2><p>## Why design $\\text{Action Space} = { Buy,Sell }$?</p><p>일반적인 트레이딩이 아닌, tax 최적화를 위해, 이익실현 연기, 손해 확정 등의 액션도 가능하다. 하지만 간단하게 하기 위해 임의로  action space를 단순화 시켰다.</p><h2 id=\"why-only-single-asset\">Why only single asset?</h2><p>각 주가의 트랜드에 맞게 따라서 최적의 전략을 추천해주는 상위 모델이 따로 있다. 따라서 본 프로젝트에서는 많이 보이는 패턴의 종목에 최적화된 모델을 만드는 것이 우선적인 목표이다. 그리고 종목에 최적화된 모델이 완성 되면, 각 모델의 output을 reward로 하는 종목 추천 모델 훈련에 사용한다.</p><h2 id=\"tlh-평가-방법\">#TLH 평가 방법</h2><p>\\(Value_{TLH} = min(G,L)(\\tau_{t_1} - \\tau_{t_2} + )\\)</p><h2 id=\"conclusion\">#Conclusion</h2><p>기존 기술적 분석 기반의 방법론들은 높은 수익률 생기는 주가의 패턴이 확실했다.</p><p>Machine Learning의 학습 기반 모델의 경우는 많은 주가 패턴 및 트랜드에서 기술적 분석 기반의 방법론들 보다는 수익률의 편차가 작았다.</p><p>@@ 상승, 박스, 하락 각각의 경우에 대한 기술적 분석 기반 방법 vs RL기반 , LSTM 기반 넣기</p><p>특히 Deep Learning 기반의 경우는 전처리가 중요하게 보인다.</p><p>@@ 스무딩 전 후 차이 예시</p><h1 id=\"2-rl-기반\">2. RL 기반</h1><hr /><h2 id=\"2-return-모델링\">2. Return 모델링</h2><h2 id=\"3-시뮬레이션-결과\">3. 시뮬레이션 결과</h2><h2 id=\"3-rnn-기반\">3. RNN 기반</h2><hr /><h2 id=\"4-f\">4. F</h2><p>LSTM</p><ul>  <li>전통적인 방법 vs RL</li>  <li>종목에 따른 최적 방법론이 다르다.</li>  <li>종목 구성 후</li>  <li>확률 과정 vs ML Base    <ul>      <li>Shift</li>    </ul>  </li></ul><p>** 어떻게 no-free lnuch</p>",
            "url": "http://0.0.0.0:8701/2023/01/01/tax-optimized-asset-management",
            
            
            
            
            
            "date_published": "2023-01-01T00:00:00+09:00",
            "date_modified": "2023-01-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2023/01/01/esg-media-ml-service",
            "title": "ESG Media Machine-Learning Service Pipeline",
            "summary": null,
            "content_text": "Link  KESG Media Portal Site  Tutorial : Simple ML Pipeline with Kubernetes + Restful API Service Infra  Kubernetes : Microk8s ( 1 Master + 2 Worker)  Github Action  MicroService Architecture : Flask + Kubernetes  Front : Dash for ProtoType  DataBase : Postgres , mySQL  GPU : RTX 3090 x 2Model  python, dash  pytorch, transformer, tensorflow  BERT (use embedding layer that fine tuned with KLUE dataset) , LightGBM, Mecab, Konlpy, Scikit-learn,1. Why Kubernetes?  When there were many samples or intermittent network problems, people had to repair them after monitoring each time.Therefore, self-healing-enabled Kubernetes automates these monitoring and repairs to reduce labor costs.  Since large-scale traffic could occur in the future, the Load Balance function was required.  Monitoring functions such as grafana can be set conveniently.  Despite the resource limitations of single-person development, many useful functions can be easily implemented.2. Why MicroService Architecture?  Service extension is planned in the future, and it is desgined to reuse existing functions by separating them into functional units.3. Why Github Action?  Organized so that functions can be applied directly from the development server to the service server through Github Action with manifest4. System Design4. Real Service ScreenshotFront    ESG Issue Analysis     Target Company Monitoring      Target Company News List        Data Center  ",
            "content_html": "<p><strong>Link</strong></p><ul>  <li><a href=\"http://portal.kresg.co.kr\" style=\"color: blue; text-decoration: underline;\">KESG Media Portal Site</a></li>  <li><a href=\"\">Tutorial : Simple ML Pipeline with Kubernetes + Restful API </a></li></ul><p><strong>Service Infra</strong></p><ul>  <li>Kubernetes : Microk8s ( 1 Master + 2 Worker)</li>  <li>Github Action</li>  <li>MicroService Architecture : Flask + Kubernetes</li>  <li>Front : Dash for ProtoType</li>  <li>DataBase : Postgres , mySQL</li>  <li>GPU : RTX 3090 x 2</li></ul><p><strong>Model</strong></p><ul>  <li>python, dash</li>  <li>pytorch, transformer, tensorflow</li>  <li>BERT (use embedding layer that fine tuned with KLUE dataset) , LightGBM, Mecab, Konlpy, Scikit-learn,</li></ul><h2 id=\"1-why-kubernetes\">1. Why Kubernetes?</h2><ul>  <li>When there were many samples or intermittent network problems, people had to repair them after monitoring each time.Therefore, self-healing-enabled Kubernetes automates these monitoring and repairs to reduce labor costs.</li>  <li>Since large-scale traffic could occur in the future, the Load Balance function was required.</li>  <li>Monitoring functions such as grafana can be set conveniently.</li>  <li>Despite the resource limitations of single-person development, many useful functions can be easily implemented.</li></ul><h2 id=\"2-why-microservice-architecture\">2. Why MicroService Architecture?</h2><ul>  <li>Service extension is planned in the future, and it is desgined to reuse existing functions by separating them into functional units.</li></ul><h2 id=\"3-why-github-action\">3. Why Github Action?</h2><ul>  <li>Organized so that functions can be applied directly from the development server to the service server through Github Action with manifest</li></ul><h2 id=\"4-system-design\">4. System Design</h2><p><img src=\"/assets/esg_media/pipeline/kube_pipeline_trans.png\" alt=\"kubernetes_pipeline\" /></p><h2 id=\"4-real-service-screenshot\">4. Real Service Screenshot</h2><p><strong>Front</strong>  <br /><img src=\"/assets/esg_media/webpage/kresg_front.png\" alt=\"front\" />  <br /><br /><strong>ESG Issue Analysis</strong>  <br /><img src=\"/assets/esg_media/webpage/kresg_issue.png\" alt=\"issue_analysis\" />  <br /><br /> <br /><strong>Target Company Monitoring</strong>  <br /><img src=\"/assets/esg_media/webpage/kresg_monitoring.png\" alt=\"monitoring\" />  <br /><br />  <br /><strong>Target Company News List</strong>  <br /><img src=\"/assets/esg_media/webpage/kresg_news_list.png\" alt=\"news\" />     <br /><br /> <br /><strong>Data Center</strong>  <br /><img src=\"/assets/esg_media/webpage/kresg_datacenter.png\" alt=\"data_center\" /></p>",
            "url": "http://0.0.0.0:8701/2023/01/01/esg-media-ml-service",
            
            
            
            
            
            "date_published": "2023-01-01T00:00:00+09:00",
            "date_modified": "2023-01-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2022/06/01/clinical-decision-support-algorithm-to-anti-pd1-therapy",
            "title": "Clinical decision support algorithm based on machine learning to assess the clinical response to anti–pd-1 therapy",
            "summary": null,
            "content_text": "A tissue origin prediction device, method of predicting the tissue origin using a genome data, and computer program1020200076756 · Filed Jun 23, 2020SummaryAnti-programmed death (PD)-1 therapy (αPD-1) has been used in patients with non-small celllung cancer (NSCLC), leading to improved outcomes. However, the outcomes of therapy are stillinsufficient, and the expression of PD-ligand 1 (PD-L1) is not always a predictor of response toαPD-1.The immuno-cancer drugs used for treatment purposes of NSCLC are typically Kitruda and Optivo. Each monthly treatment costs about $600,000 and $800,000, respectively, and costs nearly $10 million a year.But the drug doesn’t respond to all patients. Therefore, in the case of Kitruda, the ‘PD-L1 expression positive rate’ must be 50% or more to be prescribed. However, even if the conditions are satisfied and prescribed, the actual drug reaction is about 60%.I studied a drug activity prediction model using Non-FDA-approved information to help more patients get the correct prescription and reduce the cost of drug waste.Summary Idea &amp; SolutionData  Clinical data including patient characteristics  Mutations  Laboratory findings from the electronic medical recordsData Feature  Missing values ​​exist in most features. Learning inputation models separately based on the distribution of other features and their non-missing values, rather than simple mean, zero, etc. methods.  To prevent data leakage, it was reviewed directly by the clinician.Model Selection &amp; Evaluation  Proceed with model selection, including linear models, to find the appropriate complexity of the model.  Due to the small number of samples, LOOCV is used for model selection  Due to the nature of the field, some explanatory power is required, so the ensemble stage to maximize performance is not performed.  Finding samples that appear to be somewhat outliers as a result of LOOCV. (4 samples)Feature Attribution  It is very likely that there is an interaction effect between data.  Therefore, feature importance based on simple entropy is highly likely to cause errors in interpretation.  The Lime-based explanation model has a small number of samples, so it is judged that there is a lot of room for problems in fitting the local model.  For each sample, the average of the shap values ​​and the interaction value were calculated.DetailFeature engineeringGene&amp; Metastasis FeatureSparsity When judging based on the commonly used sparsity judgment criteria, it was determined that there was sparsity by the ratio of zero value.  Percentage of zero values: About \\(Gene Expression  \\in \\{0,1\\}\\),  The ratio of zero is at least 85% to a maximum of 95%. Therefore, it is judged to be sparse.  Number of observations: It does not see the sparse by observices.  Data Volatility: Because it is a binary, the conclusion is the same as that of Percenrage of zero. it is sparse.  Model performance: Unable to judge due to the limit of the number of samples.  Domain knowledge: Since there are no accurate statistics on gene expression for Korean, sparsity cannot be determined based on Domain knowledge.New Feature  To reduce sparsity, change the gene feature to a new feature that represents the total number of expressions of the associated gene.\\(\\text{driver oncogene} = \\sum{ \\text{gene expression}}\\)  Change Metastasis to “Total Metastasis” in the same way.\\(\\text{metastasis count} = \\sum{ \\text{metastasis present}}\\)  Neutrophil and Lymphocyte were replaced by the LNR (lymphocyte-to-neutrophil ratio) feature.\\(LNR = log(\\frac{Neutrophil}{Lymphocyte} + \\epsilon )\\)Model SelectionBelow is a comparison table of the eight models of the roc-auc score. It was evaluated with LOOCV (Leave one out CV).It was judged that the model required for prediction did not have to be highly complex. Therefore, we did not do model ensembles and compared only single models.Best Model Performance : LightGBMFeature AttributionIt is the average value of the SHAP value of all samples.Shap is the contribution to the predicted value of a model considering the synergistic effect of one feature and another feature, from the point of view of game theory. Since the data in the medical and bio fields are features that are difficult to assert independence, it was judged that SHAP value-based interpretation was appropriate.Looking at the results, I suspected that the persistence of non-measurable lesions might have a high correlation with the target value. Thus, the persistence of non-measurable lesions is an ordinary type of data, so we look at spearman correlation.correlation = -0.44 and p-value = 8.1e-11. That is, it was not a strong relationship, so it was used as a feature.",
            "content_html": "<h2 id=\"a-tissue-origin-prediction-device-method-of-predicting-the-tissue-origin-using-a-genome-data-and-computer-program\">A tissue origin prediction device, method of predicting the tissue origin using a genome data, and computer program</h2><h3 id=\"1020200076756--filed-jun-23-2020\">1020200076756 · Filed Jun 23, 2020</h3><h1 id=\"summary\">Summary</h1><hr /><p>Anti-programmed death (PD)-1 therapy (αPD-1) has been used in patients with non-small celllung cancer (NSCLC), leading to improved outcomes. However, the outcomes of therapy are stillinsufficient, and the expression of PD-ligand 1 (PD-L1) is not always a predictor of response toαPD-1.</p><p>The immuno-cancer drugs used for treatment purposes of NSCLC are typically Kitruda and Optivo. <br />Each monthly treatment costs about $600,000 and $800,000, respectively, and costs nearly $10 million a year.</p><p>But the drug doesn’t respond to all patients. Therefore, in the case of Kitruda, the ‘PD-L1 expression positive rate’ must be 50% or more to be prescribed. However, even if the conditions are satisfied and prescribed, the actual drug reaction is about 60%.</p><p>I studied a drug activity prediction model using Non-FDA-approved information to help more patients get the correct prescription and reduce the cost of drug waste.</p><h1 id=\"summary-idea--solution\">Summary Idea &amp; Solution</h1><hr /><h2 id=\"data\">Data</h2><ul>  <li>Clinical data including patient characteristics</li>  <li>Mutations</li>  <li>Laboratory findings from the electronic medical records</li></ul><h2 id=\"data-feature\">Data Feature</h2><ul>  <li>Missing values ​​exist in most features. Learning inputation models separately based on the distribution of other features and their non-missing values, rather than simple mean, zero, etc. methods.</li>  <li>To prevent data leakage, it was reviewed directly by the clinician.</li></ul><h2 id=\"model-selection--evaluation\">Model Selection &amp; Evaluation</h2><ul>  <li>Proceed with model selection, including linear models, to find the appropriate complexity of the model.</li>  <li>Due to the small number of samples, LOOCV is used for model selection</li>  <li>Due to the nature of the field, some explanatory power is required, so the ensemble stage to maximize performance is not performed.</li>  <li>Finding samples that appear to be somewhat outliers as a result of LOOCV. (4 samples)</li></ul><h2 id=\"feature-attribution\">Feature Attribution</h2><ul>  <li>It is very likely that there is an interaction effect between data.</li>  <li>Therefore, feature importance based on simple entropy is highly likely to cause errors in interpretation.</li>  <li>The Lime-based explanation model has a small number of samples, so it is judged that there is a lot of room for problems in fitting the local model.</li>  <li>For each sample, the average of the shap values ​​and the interaction value were calculated.</li></ul><p><img src=\"/assets/paper_cdss/CDSS_main.jpg\" alt=\"main_fig\" /><img src=\"/assets/paper_cdss/paper_front.png\" alt=\"front\" /></p><p><br /></p><h1 id=\"detail\">Detail</h1><hr /><h2 id=\"feature-engineering\">Feature engineering</h2><h3 id=\"gene-metastasis-feature\">Gene&amp; Metastasis Feature</h3><p><strong>Sparsity</strong> <br /></p><p>When judging based on the commonly used sparsity judgment criteria, it was determined that there was sparsity by the ratio of zero value.</p><ul>  <li>Percentage of zero values: About \\(Gene Expression  \\in \\{0,1\\}\\),  The ratio of zero is at least 85% to a maximum of 95%. Therefore, it is judged to be sparse.</li>  <li>Number of observations: It does not see the sparse by observices.</li>  <li>Data Volatility: Because it is a binary, the conclusion is the same as that of Percenrage of zero. it is sparse.</li>  <li>Model performance: Unable to judge due to the limit of the number of samples.</li>  <li>Domain knowledge: Since there are no accurate statistics on gene expression for Korean, sparsity cannot be determined based on Domain knowledge.</li></ul><p><strong>New Feature</strong></p><ul>  <li>To reduce sparsity, change the gene feature to a new feature that represents the total number of expressions of the associated gene.\\(\\text{driver oncogene} = \\sum{ \\text{gene expression}}\\)</li>  <li>Change Metastasis to “Total Metastasis” in the same way.\\(\\text{metastasis count} = \\sum{ \\text{metastasis present}}\\)</li>  <li>Neutrophil and Lymphocyte were replaced by the LNR (lymphocyte-to-neutrophil ratio) feature.\\(LNR = log(\\frac{Neutrophil}{Lymphocyte} + \\epsilon )\\)</li></ul><p><br /></p><h2 id=\"model-selection\">Model Selection</h2><p>Below is a comparison table of the eight models of the roc-auc score. It was evaluated with LOOCV (Leave one out CV).It was judged that the model required for prediction did not have to be highly complex. Therefore, we did not do model ensembles and compared only single models.<br /><img src=\"/assets/paper_cdss/paper_compare.png\" alt=\"score\" /><br /></p><p><strong>Best Model Performance : LightGBM</strong></p><p><img src=\"/assets/paper_cdss/paper_score.png\" alt=\"score\" /></p><p><br /></p><h2 id=\"feature-attribution-1\">Feature Attribution</h2><hr /><p>It is the average value of the SHAP value of all samples.<br />Shap is the contribution to the predicted value of a model considering the synergistic effect of one feature and another feature, from the point of view of game theory. <br />Since the data in the medical and bio fields are features that are difficult to assert independence, it was judged that SHAP value-based interpretation was appropriate.</p><p><img src=\"/assets/paper_cdss/paper_shap_val.png\" alt=\"shap\" /></p><p>Looking at the results, I suspected that the persistence of non-measurable lesions might have a high correlation with the target value. Thus, the persistence of non-measurable lesions is an ordinary type of data, so we look at spearman correlation.correlation = -0.44 and p-value = 8.1e-11. That is, it was not a strong relationship, so it was used as a feature.</p>",
            "url": "http://0.0.0.0:8701/2022/06/01/clinical-decision-support-algorithm-to-anti-pd1-therapy",
            
            
            
            
            
            "date_published": "2022-06-01T00:00:00+09:00",
            "date_modified": "2022-06-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2020/06/01/ctd-squared-pancancer-chemosensitivity-dream-challenge",
            "title": "CTD-squared Pancancer Chemosensitivity DREAM Challenge",
            "summary": null,
            "content_text": "Gene Expression Searching and machine learning model for Chemosensitivity Predictioncontents  Data  Workflow &amp; Key ideas  Conclusion &amp; Discussion  Reference  Feature Engineering  If you want to see entire predictive system concept, see section 2  If you want to detail of machine learning strategies, see section 5      The data used in this work are all public data.    In the middle, we changed the working environment to the AWS environment. The code for this repository is still unorganized, so it can be messy. And because the data is very large, I didn’t put it in the repository.  1. DataUsed Dataset  CCLE basal expression &amp; meta info  L1000 phase1, phase2 lv.5  CTRP AUC  DEMETER2 normalized dependency score for 515 cell lines  PANACEA gene expressionPreprocessingUse the following five data to describe the characteristics of the cell line.Histology and basal expressions for 515 cell lines in CCLE ,TF activity inference score and Pathway inference score were calculated from the CCLE basal expression value using Viper. PROGENy, respectively.The NA values within the DEMETER2 score were imputed with average values per cell lines.For the data to describe the characteristics of the drug, only post-treatment expression values were used.Signatures for overlapping 326 drugs in CTRP and L1000 are selected and only 973 experimentally measured genes were used to normalize by MODZ.The given PANACEA expression values were also normalized by the MODZ method across the cell lines.\\[\\mathcal{D_f} = \\{  (x_i,y_i) \\vert  f \\in F\\}\\]where \\(y\\) is auc value of perturbation, \\(x_i\\) is feature of each sample.\\(\\mathcal{S}\\) is feature class, \\(\\mathcal{S} = \\{TF,PRO,HIST,GENE,CCLE,D2_{mean} \\}\\), \\(\\mathcal{F}\\) is  feature set, \\(\\mathcal{F} = \\{f_i \\vert  i \\in S \\}\\)\\[f^* = \\{ TF,HIST,GENE,CCLE,D2_{mean} \\}\\]  2. Workflow &amp; Key ideas Step1. Searching similar drugs for hidden drugsFirst, we performed the gene expression signature search via spearman correlation calculation. As a reference data, L1000, which was signaturized for each drug through MODZ, and PANACEA was used as a query for this. The similarity between drugs was calculated by spearman correlation. We chose similar drugs with the following criteria. By calculating robust z-score for the similarity matrix, only drugs corresponding to more than 70% of the max value of z-score were collected for each query drug. For example, for the above method, there are 7 and 19 drugs selected as drugs similar to cmpd_KW and cmpd_WW, respectively.     Step2. Modeling &amp; PredictionAs shown above, a drug-specific model was created using only the selected perturbations for each hidden drug.The model approached the regression problem using the GBDT to predict the AUC value according to the cell line-drug pairs given in the CTRP and used features describing the above mentioned. We use CART for base learner with histogram optimized approximate greedy algorithm.  We finally found out that roughly 3000 features exhibited the best performance, and we actually saw that performance was not significantly reduced even if we reduced to 7 feature sets through dimension reduction.  The most efficient dimensional reduction model was the Autoencoder model with MSE + Correlation*0.7 as the objective, but due to the complicated analysis, we use the gradient boosting method with the CART for base learner and use a very small number of sampled features. And by overfitting each prediction model to a specific set of drugs,  final ensemble model had better generalization performance since the diversity of models increased.     Step3. EnsembleFor generalization performance, we implemented a model ensemble. Using the results of varying the threshold value from 20% to 90% of max with z-score as shown above, correlation between the results of each model was compared. To use more diverse models, eight models were finally selected in the order in which they were less correlated with each other, and the predicted results were integrated to create a final presentation file.Detail procedure is like this.\\(\\mathcal{M} \\textrm{ is set of models,} \\mathcal{M} := \\{ M_1 , \\cdots , M_n \\}, \\mathcal{D} : \\mathcal{M} \\times  \\mathcal{M} \\rightarrow \\mathcal{R} \\textrm{ is distance function}\\) and we define average distance over each model.\\[\\mathcal{D}_{avg}(M_i) = \\frac{1}{| \\mathcal{M} \\setminus { \\{i\\} }  |}  \\sum_{m \\in \\mathcal{M} \\backslash {\\{i\\}} } \\mathcal{D}(M_i,m)\\]next, we select candidate for ensemble .\\[\\mathcal{M}_{candidate} :=\\{  \\mathcal{M}_i | \\mathcal{D}_{avg}(M_i) \\ngeq \\textrm{ 90th percentile} \\}\\]finaly, define of ensemble score is like below .\\[S_{ensemble} = exp( \\frac{1}{|\\mathcal{M}_{candidate}|}  \\sum_{m \\in \\mathcal{M}_{candidate}} log( \\mathcal{D}_{avg}(m)) )\\]3. Conclusion &amp; DiscussionWe started from the assumption that we could deduce the MoA of the drug via post-treatment gene expression on the drug.It is difficult to predict drug sensitivities that have specific targets and specific pathways(Koras, K et al. 2020). So, we recognized the need to make models for each drug, and we tried many things, such as looking at which gene has high coefficient for each drug by predicting AUC with only gene expression, in addition to the methods described above. Our experiments have also shown that it is better to make a model for each drugs than to use one model predicting the AUC for all drugs.Each cell line has its own unique characteristics, so it is very meaningful to use it as a feature that can explain it. Predicting the drug sensitivities for each cell line will be very useful in selecting cell lines in experimental screening and also valuable in the field of new drug development in reducing costs.Since we didn’t have enough time to find the optimal model, we had no choice but to use the naive experimental results, so I think we can improve the predictive performance through more accurate experiments.4. References  CTD-squared Pancancer Chemosensitivity DREAM Challenge (syn21763589)  CTD-squared BeatAML DREAM Challenge (syn20940518)  Rees, M., Seashore-Ludlow, B., Cheah, J., Adams, D., Price, E., Gill, S., Javaid, S., Coletti, M., Jones, V., Bodycombe, N., Soule, C., Alexander, B., Li, A., Montgomery, P., Kotz, J., Hon, C., Munoz, B., Liefeld, T., Dančík, V., Haber, D., Clish, C., Bittker, J., Palmer, M., Wagner, B., Clemons, P., Shamji, A., Schreiber, S. (2016). Correlating chemical sensitivity and basal gene expression reveals mechanism of action Nature Chemical Biology  12(2), 109-116. https://dx.doi.org/10.1038/nchembio.1986  Subramanian, A., Narayan, R., Corsello, S., Peck, D., Natoli, T., Lu, X., Gould, J., Davis, J., Tubelli, A., Asiedu, J., Lahr, D., Hirschman, J., Liu, Z., Donahue, M., Julian, B., Khan, M., Wadden, D., Smith, I., Lam, D., Liberzon, A., Toder, C., Bagul, M., Orzechowski, M., Enache, O., Piccioni, F., Johnson, S., Lyons, N., Berger, A., Shamji, A., Brooks, A., Vrcic, A., Flynn, C., Rosains, J., Takeda, D., Hu, R., Davison, D., Lamb, J., Ardlie, K., Hogstrom, L., Greenside, P., Gray, N., Clemons, P., Silver, S., Wu, X., Zhao, W., Read-Button, W., Wu, X., Haggarty, S., Ronco, L., Boehm, J., Schreiber, S., Doench, J., Bittker, J., Root, D., Wong, B., Golub, T. (2017). A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles Cell 171(6), 1437 1452.e17. https://dx.doi.org/10.1016/j.cell.2017.10.049  Szalai, B., Subramanian, V., Holland, C., Alföldi, R., Pusk, L., Saez-Rodriguez, J. (2019). Signatures of cell death and proliferation in perturbation transcriptomics data—from confounding factor to effective prediction Nucleic Acids Research  47(19), 10010-10026. https://dx.doi.org/10.1093/nar/gkz805  Koras, K., Juraeva, D., Kreis, J., Mazur, J., Staub, E., Szczurek, E. (2020). Feature selection strategies for drug sensitivity prediction Scientific Reports 10(1), 9377. https://dx.doi.org/10.1038/s41598-020-65927-9  Garcia-Alonso L, Holland C, Ibrahim M, Turei D, Saez-Rodriguez J (2019). “Benchmark and integration of resources for the estimation of human transcription factor activities.” Genome Research. doi: 10.1101/gr.240663.118.  Schubert M, Klinger B, Klünemann M, Sieber A, Uhlitz F, Sauer S, Garnett MJ, Blüthgen N, Saez-Rodriguez J. “Perturbation-response genes reveal signaling footprints in cancer gene expression.” Nature Communications: 10.1038/s41467-017-02391-65. Feature Engineering1. Data Integration   Different public datasets have different gene types. Alternatively, you can use a gene set that you deem valid based on domain knowledge. Strategies other than intersection result in missing value unconditionally. Therefore, the method of imputating the missing value must also be selected.      In this project, we compared two methods using gene sets judged to be valid through intersection and paper search, and found that the performance of intersection is similar. Therefore, we used an intersection geneset with a small data size. (973 genes.)2. Demesional reduction      Unable to find any studies for manifolds of data between total expression amount + chemical reaction amount. Therefore, Autoencoder was used.        Use cosine similarity and pearsons R as the evaluation metric. In a situation where the process of generating genetic data is not guaranteed to be the same, it is difficult to normalize when operating between different dataset. Therefore, Cosine similarity was used as the main and Pearson correlation coefficient was used as an adjunct.        VAE vs AE comparison. (see ‘/code_clean/st_04_mapping_drug_378norm_ctrp_auto_encoder/’)      Why perform demesional reduction and use cosine similarity for AE?  -&gt; I found that the genomic data we use is biased by sequencing machines and processes in training machine learning models. This was previously based on cancer tumor classification tests and genomic data.  These differences mainly occur in relative expression amounts, and it was experimentally found that the types of genes expressed are generally consistent.  This is why I used AE and cosine similarity as an evaluation metric.Why not UMAP(Uniform Manifold Approximation and Projection)? -&gt; In the case of UMAP, it is necessary to design a quality evaluation method of the pre-distance metric, search for the optimal metric, and optimize the projection parameters. And since the model description is not necessary for this competition, it was not used for the sake of time.Why not linear dimensionality reduction (like PCA, NMF)?   -&gt; Because the data is high-dimensional and sparse, the linear method does not fit.3. DNN encoder feature    -&gt; It is a method determined in the engineering process to create optimal features.  Experimentally tried several feature engineering and applied them because we achieved the best CV-score.",
            "content_html": "<h1 id=\"gene-expression-searching-and-machine-learning-model-for-chemosensitivity-prediction\">Gene Expression Searching and machine learning model for Chemosensitivity Prediction</h1><hr /><p><strong><em>contents</em></strong></p><ol>  <li>Data</li>  <li>Workflow &amp; Key ideas</li>  <li>Conclusion &amp; Discussion</li>  <li>Reference</li>  <li>Feature Engineering</li></ol><ul>  <li>If you want to see entire predictive system concept, see section 2</li>  <li>If you want to detail of machine learning strategies, see section 5</li>  <li>    <p>The data used in this work are all public data.</p>  </li>  <li>In the middle, we changed the working environment to the AWS environment. The code for this repository is still unorganized, so it can be messy. And because the data is very large, I didn’t put it in the repository.</li></ul><p>  </p><h1 id=\"1-data\">1. Data</h1><h3 id=\"used-dataset\"><strong>Used Dataset</strong></h3><ul>  <li>CCLE basal expression &amp; meta info</li>  <li>L1000 phase1, phase2 lv.5</li>  <li>CTRP AUC</li>  <li>DEMETER2 normalized dependency score for 515 cell lines</li>  <li>PANACEA gene expression</li></ul><h3 id=\"preprocessing\"><strong>Preprocessing</strong></h3><p>Use the following five data to describe the characteristics of the cell line.Histology and basal expressions for 515 cell lines in CCLE ,TF activity inference score and Pathway inference score were calculated from the CCLE basal expression value using Viper. PROGENy, respectively.The NA values within the DEMETER2 score were imputed with average values per cell lines.</p><p>For the data to describe the characteristics of the drug, only post-treatment expression values were used.Signatures for overlapping 326 drugs in CTRP and L1000 are selected and only 973 experimentally measured genes were used to normalize by MODZ.The given PANACEA expression values were also normalized by the MODZ method across the cell lines.</p>\\[\\mathcal{D_f} = \\{  (x_i,y_i) \\vert  f \\in F\\}\\]<p>where \\(y\\) is auc value of perturbation, \\(x_i\\) is feature of each sample.</p><p>\\(\\mathcal{S}\\) is feature class, \\(\\mathcal{S} = \\{TF,PRO,HIST,GENE,CCLE,D2_{mean} \\}\\), \\(\\mathcal{F}\\) is  feature set, \\(\\mathcal{F} = \\{f_i \\vert  i \\in S \\}\\)</p>\\[f^* = \\{ TF,HIST,GENE,CCLE,D2_{mean} \\}\\]<p>  </p><h1 id=\"2-workflow--key-ideas\">2. Workflow &amp; Key ideas</h1><p> </p><h3 id=\"step1-searching-similar-drugs-for-hidden-drugs\">Step1. Searching similar drugs for hidden drugs</h3><hr /><p>First, we performed the gene expression signature search via spearman correlation calculation. As a reference data, L1000, which was signaturized for each drug through MODZ, and PANACEA was used as a query for this. The similarity between drugs was calculated by spearman correlation. We chose similar drugs with the following criteria. By calculating robust z-score for the similarity matrix, only drugs corresponding to more than 70% of the max value of z-score were collected for each query drug. For example, for the above method, there are 7 and 19 drugs selected as drugs similar to cmpd_KW and cmpd_WW, respectively.</p><p align=\"center\">    <img width=\"400\" src=\"/assets/2020/06_01/z_score_thereshold.png\" /></p><p> </p><h3 id=\"step2-modeling--prediction\">Step2. Modeling &amp; Prediction</h3><hr /><p>As shown above, a drug-specific model was created using only the selected perturbations for each hidden drug.The model approached the regression problem using the GBDT to predict the AUC value according to the cell line-drug pairs given in the CTRP and used features describing the above mentioned. We use CART for base learner with histogram optimized approximate greedy algorithm.  We finally found out that roughly 3000 features exhibited the best performance, and we actually saw that performance was not significantly reduced even if we reduced to 7 feature sets through dimension reduction.  The most efficient dimensional reduction model was the Autoencoder model with MSE + Correlation*0.7 as the objective, but due to the complicated analysis, we use the gradient boosting method with the CART for base learner and use a very small number of sampled features. And by overfitting each prediction model to a specific set of drugs,  final ensemble model had better generalization performance since the diversity of models increased.</p><p align=\"center\">    <img width=\"800\" src=\"/assets/2020/06_01/structure.png\" alt=\"Material Bread logo\" /></p><p> </p><h3 id=\"step3-ensemble\">Step3. Ensemble</h3><p>For generalization performance, we implemented a model ensemble. Using the results of varying the threshold value from 20% to 90% of max with z-score as shown above, correlation between the results of each model was compared. To use more diverse models, eight models were finally selected in the order in which they were less correlated with each other, and the predicted results were integrated to create a final presentation file.Detail procedure is like this.</p><p>\\(\\mathcal{M} \\textrm{ is set of models,} \\mathcal{M} := \\{ M_1 , \\cdots , M_n \\}, \\mathcal{D} : \\mathcal{M} \\times  \\mathcal{M} \\rightarrow \\mathcal{R} \\textrm{ is distance function}\\) and we define average distance over each model.</p>\\[\\mathcal{D}_{avg}(M_i) = \\frac{1}{| \\mathcal{M} \\setminus { \\{i\\} }  |}  \\sum_{m \\in \\mathcal{M} \\backslash {\\{i\\}} } \\mathcal{D}(M_i,m)\\]<p>next, we select candidate for ensemble .</p>\\[\\mathcal{M}_{candidate} :=\\{  \\mathcal{M}_i | \\mathcal{D}_{avg}(M_i) \\ngeq \\textrm{ 90th percentile} \\}\\]<p>finaly, define of ensemble score is like below .</p>\\[S_{ensemble} = exp( \\frac{1}{|\\mathcal{M}_{candidate}|}  \\sum_{m \\in \\mathcal{M}_{candidate}} log( \\mathcal{D}_{avg}(m)) )\\]<p><br /><br /></p><h1 id=\"3-conclusion--discussion\">3. Conclusion &amp; Discussion</h1><p>We started from the assumption that we could deduce the MoA of the drug via post-treatment gene expression on the drug.It is difficult to predict drug sensitivities that have specific targets and specific pathways(Koras, K et al. 2020). So, we recognized the need to make models for each drug, and we tried many things, such as looking at which gene has high coefficient for each drug by predicting AUC with only gene expression, in addition to the methods described above. Our experiments have also shown that it is better to make a model for each drugs than to use one model predicting the AUC for all drugs.Each cell line has its own unique characteristics, so it is very meaningful to use it as a feature that can explain it. Predicting the drug sensitivities for each cell line will be very useful in selecting cell lines in experimental screening and also valuable in the field of new drug development in reducing costs.Since we didn’t have enough time to find the optimal model, we had no choice but to use the naive experimental results, so I think we can improve the predictive performance through more accurate experiments.</p><p><br /><br /></p><h1 id=\"4-references\">4. References</h1><ol>  <li>CTD-squared Pancancer Chemosensitivity DREAM Challenge (syn21763589)</li>  <li>CTD-squared BeatAML DREAM Challenge (syn20940518)</li>  <li>Rees, M., Seashore-Ludlow, B., Cheah, J., Adams, D., Price, E., Gill, S., Javaid, S., Coletti, M., Jones, V., Bodycombe, N., Soule, C., Alexander, B., Li, A., Montgomery, P., Kotz, J., Hon, C., Munoz, B., Liefeld, T., Dančík, V., Haber, D., Clish, C., Bittker, J., Palmer, M., Wagner, B., Clemons, P., Shamji, A., Schreiber, S. (2016). Correlating chemical sensitivity and basal gene expression reveals mechanism of action Nature Chemical Biology  12(2), 109-116. https://dx.doi.org/10.1038/nchembio.1986</li>  <li>Subramanian, A., Narayan, R., Corsello, S., Peck, D., Natoli, T., Lu, X., Gould, J., Davis, J., Tubelli, A., Asiedu, J., Lahr, D., Hirschman, J., Liu, Z., Donahue, M., Julian, B., Khan, M., Wadden, D., Smith, I., Lam, D., Liberzon, A., Toder, C., Bagul, M., Orzechowski, M., Enache, O., Piccioni, F., Johnson, S., Lyons, N., Berger, A., Shamji, A., Brooks, A., Vrcic, A., Flynn, C., Rosains, J., Takeda, D., Hu, R., Davison, D., Lamb, J., Ardlie, K., Hogstrom, L., Greenside, P., Gray, N., Clemons, P., Silver, S., Wu, X., Zhao, W., Read-Button, W., Wu, X., Haggarty, S., Ronco, L., Boehm, J., Schreiber, S., Doench, J., Bittker, J., Root, D., Wong, B., Golub, T. (2017). A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles Cell 171(6), 1437 1452.e17. https://dx.doi.org/10.1016/j.cell.2017.10.049</li>  <li>Szalai, B., Subramanian, V., Holland, C., Alföldi, R., Pusk, L., Saez-Rodriguez, J. (2019). Signatures of cell death and proliferation in perturbation transcriptomics data—from confounding factor to effective prediction Nucleic Acids Research  47(19), 10010-10026. https://dx.doi.org/10.1093/nar/gkz805</li>  <li>Koras, K., Juraeva, D., Kreis, J., Mazur, J., Staub, E., Szczurek, E. (2020). Feature selection strategies for drug sensitivity prediction Scientific Reports 10(1), 9377. https://dx.doi.org/10.1038/s41598-020-65927-9</li>  <li>Garcia-Alonso L, Holland C, Ibrahim M, Turei D, Saez-Rodriguez J (2019). “Benchmark and integration of resources for the estimation of human transcription factor activities.” Genome Research. doi: 10.1101/gr.240663.118.</li>  <li>Schubert M, Klinger B, Klünemann M, Sieber A, Uhlitz F, Sauer S, Garnett MJ, Blüthgen N, Saez-Rodriguez J. “Perturbation-response genes reveal signaling footprints in cancer gene expression.” Nature Communications: 10.1038/s41467-017-02391-6</li></ol><p><br /><br /></p><h1 id=\"5-feature-engineering\">5. Feature Engineering</h1><p><strong>1. Data Integration</strong>   <br />Different public datasets have different gene types. Alternatively, you can use a gene set that you deem valid based on domain knowledge. Strategies other than intersection result in missing value unconditionally. Therefore, the method of imputating the missing value must also be selected.     <br /> In this project, we compared two methods using gene sets judged to be valid through intersection and paper search, and found that the performance of intersection is similar. Therefore, we used an intersection geneset with a small data size. (973 genes.)</p><p><strong>2. Demesional reduction</strong></p><ul>  <li>    <p>Unable to find any studies for manifolds of data between total expression amount + chemical reaction amount. Therefore, Autoencoder was used.</p>  </li>  <li>    <p>Use cosine similarity and pearsons R as the evaluation metric. In a situation where the process of generating genetic data is not guaranteed to be the same, it is difficult to normalize when operating between different dataset. Therefore, Cosine similarity was used as the main and Pearson correlation coefficient was used as an adjunct.</p>  </li>  <li>    <p>VAE vs AE comparison. (see ‘/code_clean/st_04_mapping_drug_378norm_ctrp_auto_encoder/’)</p>  </li></ul><p align=\"center\">    <img width=\"600\" src=\"/assets/2020/06_01/vae_ae.png\" alt=\"Material Bread logo\" /></p><p><br /></p><p><strong>Why perform demesional reduction and use cosine similarity for AE?</strong>  <br />-&gt; I found that the genomic data we use is biased by sequencing machines and processes in training machine learning models. This was previously based on cancer tumor classification tests and genomic data.  <br /><br />These differences mainly occur in relative expression amounts, and it was experimentally found that the types of genes expressed are generally consistent.  <br /><br />This is why I used AE and cosine similarity as an evaluation metric.</p><p><br /></p><p><strong>Why not UMAP(Uniform Manifold Approximation and Projection)?</strong><br /> -&gt; In the case of UMAP, it is necessary to design a quality evaluation method of the pre-distance metric, search for the optimal metric, and optimize the projection parameters. And since the model description is not necessary for this competition, it was not used for the sake of time.</p><p><br /></p><p><strong>Why not linear dimensionality reduction (like PCA, NMF)?</strong>  <br /> -&gt; Because the data is high-dimensional and sparse, the linear method does not fit.</p><p><br /></p><p><strong>3. DNN encoder feature</strong>    <br />-&gt; It is a method determined in the engineering process to create optimal features.  <br /><br />Experimentally tried several feature engineering and applied them because we achieved the best CV-score.</p>",
            "url": "http://0.0.0.0:8701/2020/06/01/ctd-squared-pancancer-chemosensitivity-dream-challenge",
            
            
            
            
            
            "date_published": "2020-06-01T00:00:00+09:00",
            "date_modified": "2020-06-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2019/12/24/methods-for-providing-information-about-responses-to-cancer-immunotherapy-and-devices-using-the-same",
            "title": "Methods for providing information about responses to cancer immunotherapy and devices using the same",
            "summary": null,
            "content_text": "Info  10-2021-0081547  Filed Dec 24, 2019Please refer to the following linkPostPaperPatent Cover",
            "content_html": "<h2 id=\"info\">Info</h2><ul>  <li>10-2021-0081547</li>  <li>Filed Dec 24, 2019</li></ul><p><br /></p><p><strong><em>Please refer to the following link</em></strong><a href=\"/__posts/2022-6-01-Clinical decision support algorithm to anti–pd-1 therapy.md\">Post</a><br /><a href=\"https://www.ejcancer.com/article/S0959-8049(21)00328-2/fulltext#%20\">Paper</a></p><p><br /></p><h3 id=\"patent-cover\">Patent Cover</h3><p><img src=\"/assets/patent_pd/patent_pdl1_front.png\" alt=\"score\" /></p>",
            "url": "http://0.0.0.0:8701/2019/12/24/methods-for-providing-information-about-responses-to-cancer-immunotherapy-and-devices-using-the-same",
            
            
            
            
            
            "date_published": "2019-12-24T00:00:00+09:00",
            "date_modified": "2019-12-24T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2019/12/01/gimhae-fire-prediction-competition",
            "title": "Gimhae Fire Prediction Competition",
            "summary": null,
            "content_text": "please go to below link for code and detail explain.Code and data available.go to repository01 EDA and Basic Feature engineeringJupyter notebook : 01 EDA and Basic Feature engineering  Basic feature preprocessing using EDA and domain knowledgeFirst, you need to check whether the data treated as NaN are missing or sparse.Then, the type of data is checked, and pre-processing and feature engineering are performed accordingly.Find answers to the questions below here.    A. Missing or Sparse?  B. What type of Missing or Sparse?  C. If values type is missing, is there any meaning of missing?02 Experimental Feature engineeringJupyter notebook : 02 Experimental Feature engineering  Feature engineering based on Cross Validation score and Test score.Base on Cross Validation Score01 convert missing value to min value : 강수량 prcpttn ()  In the feature of precipitation, NaN is judged to be unmeasurable because there is no precipitation. change to minimum value 002 Fill features of categorical and binary type with the most frequent values  Due to the time relationship, the imputation model is not trained separately, and is processed as the most frequent value03 Numeric type feature missing value handling  Processing based on domain knowledgeto zero  - ttl_grnd_flr : Sum of above-ground floors of buildings        - ttl_dwn_fr : Sum of basement floors of buildings     fill with mean value  Since the following features have a low null_ratio, better results can be obtained by imputation by creating k-mean or a separate prediction model.  As a matter of time, after imputation as an average, trials of other methods were followed.  - tmprtr : temperature (c)      - wnd_spd : wind speed      - wnd_drctn : wind direction      - hmdt : humidity     - hm_cnt : Administrative district Population     - bldng_ar : Building area      - fr_mn_cnt : Personnel of the fire department in charge    04 Target encoding with smoothing  Experimentation with valid encoding methods  1. target encoding  2. target encoding + smoothing  3. target encoding + noise (0.1)  4. target encoding + noise (0.4)  5. target encoding + smoothing + noise (0.1)  6. target encoding + smoothing + noise (0.4)05 Electrocity and Gas usage  When looking at the data distribution, there are samples with no usage.  Assuming that this would be an empty house or an unmanaged building, I created the feature as shown below.  In the case of a building without electricity, it is assumed that the risk of fire will be high due to lack of management.  Fire has nothing to do with usage, so it is expressed in binaryele_engry_us : Electricity usage for a specific period    gas_engry_us : Gas usage for a specific period    1 -&gt; A house that is being used or inhabited    0 -&gt; A building that is obsolete.    In 01_EDA_Missing_Value.ipynb, check that min value = 0 of electricity and gas consumption data.fr_mn_cnt: Number of fire department personnelThe number of fire department personnel in the jurisdiction is limited to a set  Assume that fire department personnel are assigned according to the size of the area and the frequency of fire occurrence.Set Binary to 1 if more than 100, 0 if less than 100    Based on test scoreMultiple encoding testsJupyter notebook : Experiment result LightgbmJupyter notebook : Experiment result Xgboost Feature engineeringwnd_drctn (0.08 score up)    Assuming that the wind direction is different for each season, there is a possibility of fire depending on the direction of the season  Data categorization into 4 types according to wind direction  Apply binning to wind direction (wnd_drctn)bin_hour : created feature (0.03 score up)    Assume that it will be difficult to report a fire at dawn.  As a result of the check, according to the statistics of Seoul, there is a difference in the occurrence of fires according to time zones.  Similarly, Gimhae Fire &amp; Marine Insurance determined that there was a difference in the frequency of fire occurrence by time period, and categorized data by time period.03 Data distribution control  Check the distribution of Train / Validation / Test data. Control the distribution similarly to the actual test data to be used.      What is unusual about this competition is that validation data was given. Therefore, it was assumed that at least the validation data would have a similar distribution to the test data, but the difference and correlation between the CV score and the LB score could not be derived, so the work was performed assuming that the distribution would be different.    Adverserial validation 및 UMAP dimension reduction visualization 으로 확인Jupyter notebook : Adverserial ValidationJupyter notebook : UMAP dimension reduction visualization04 Sampling  The following sampling strategies were used to control for differences in data distribution.1. A dimensionally reduced, low-dimensional vector that samples only samples that are close to the test sample.  euclidean distanceThe black dot is the test data. Model training proceeds by removing samples that are far from the black point distance and sampling only samples that are close to the black point.The criterion of closeness was experimentally determined.2. Picking with Predicted Probabilities  Create a train or not, validation or not, test or not classification model and extract train and validation samples that are indistinguishable from test.  Probability distribution of predicted values for test data or not.  Even though it is test data, there are also samples that are not test data. At this time, select training and validation samples that are predicted with a similar probability to the test data. (mainly between 0.05 and 0.15)  Conversely, samples predicted as test data are also selected even though they are not test data. (mainly between 0.8 and 1.0)",
            "content_html": "<p>please go to below link for code and detail explain.Code and data available.<a href=\"[/assets/2020/01_23/canberra.png](https://github.com/jaewoo-so/gimhae_fire_prediction)\">go to repository</a></p><h1 id=\"01-eda-and-basic-feature-engineering\">01 EDA and Basic Feature engineering</h1><hr /><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_final/01_EDA_Missing_Value_Basic_Processing.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : 01 EDA and Basic Feature engineering</a></p><ul>  <li>Basic feature preprocessing using EDA and domain knowledge</li></ul><p>First, you need to check whether the data treated as NaN are missing or sparse.Then, the type of data is checked, and pre-processing and feature engineering are performed accordingly.</p><p>Find answers to the questions below here.  <br />  <br />A. Missing or Sparse?  <br />B. What type of Missing or Sparse?  <br />C. If values type is missing, is there any meaning of missing?</p><h1 id=\"02-experimental-feature-engineering\">02 Experimental Feature engineering</h1><hr /><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_final/01_EDA_Missing_Value_Basic_Processing.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : 02 Experimental Feature engineering</a></p><ul>  <li>Feature engineering based on Cross Validation score and Test score.</li></ul><h2 id=\"base-on-cross-validation-score\">Base on Cross Validation Score</h2><h3 id=\"01-convert-missing-value-to-min-value--강수량-prcpttn-\">01 convert missing value to min value : 강수량 prcpttn ()</h3><ul>  <li>In the feature of precipitation, NaN is judged to be unmeasurable because there is no precipitation. change to minimum value 0</li></ul><h3 id=\"02-fill-features-of-categorical-and-binary-type-with-the-most-frequent-values\">02 Fill features of categorical and binary type with the most frequent values</h3><ul>  <li>Due to the time relationship, the imputation model is not trained separately, and is processed as the most frequent value</li></ul><h3 id=\"03-numeric-type-feature-missing-value-handling\">03 Numeric type feature missing value handling</h3><ul>  <li>Processing based on domain knowledge</li></ul><p><strong>to zero</strong></p><pre><code>  - ttl_grnd_flr : Sum of above-ground floors of buildings        - ttl_dwn_fr : Sum of basement floors of buildings     </code></pre><p><strong>fill with mean value</strong>  <br />Since the following features have a low null_ratio, better results can be obtained by imputation by creating k-mean or a separate prediction model.  <br />As a matter of time, after imputation as an average, trials of other methods were followed.</p><pre><code>  - tmprtr : temperature (c)      - wnd_spd : wind speed      - wnd_drctn : wind direction      - hmdt : humidity     - hm_cnt : Administrative district Population     - bldng_ar : Building area      - fr_mn_cnt : Personnel of the fire department in charge    </code></pre><h3 id=\"04-target-encoding-with-smoothing\">04 Target encoding with smoothing</h3><ul>  <li>Experimentation with valid encoding methods</li></ul><pre><code>  1. target encoding  2. target encoding + smoothing  3. target encoding + noise (0.1)  4. target encoding + noise (0.4)  5. target encoding + smoothing + noise (0.1)  6. target encoding + smoothing + noise (0.4)</code></pre><h3 id=\"05-electrocity-and-gas-usage\">05 Electrocity and Gas usage</h3><ul>  <li>When looking at the data distribution, there are samples with no usage.</li>  <li>Assuming that this would be an empty house or an unmanaged building, I created the feature as shown below.</li>  <li>In the case of a building without electricity, it is assumed that the risk of fire will be high due to lack of management.</li>  <li>Fire has nothing to do with usage, so it is expressed in binary</li></ul><pre><code>ele_engry_us : Electricity usage for a specific period    gas_engry_us : Gas usage for a specific period    1 -&gt; A house that is being used or inhabited    0 -&gt; A building that is obsolete.    </code></pre><p>In 01_EDA_Missing_Value.ipynb, check that min value = 0 of electricity and gas consumption data.</p><h3 id=\"fr_mn_cnt-number-of-fire-department-personnel\">fr_mn_cnt: Number of fire department personnel</h3><p>The number of fire department personnel in the jurisdiction is limited to a set  <br />Assume that fire department personnel are assigned according to the size of the area and the frequency of fire occurrence.</p><pre><code>Set Binary to 1 if more than 100, 0 if less than 100    </code></pre><h2 id=\"based-on-test-score\">Based on test score</h2><h3 id=\"multiple-encoding-tests\">Multiple encoding tests</h3><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_exp/sojaewoo/data_1111_version/code_v07/001_1_encoding_evaluation_lgb.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : Experiment result Lightgbm</a></p><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_exp/sojaewoo/data_1111_version/code_v07/001_1_encoding_evaluation_xgb.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : Experiment result Xgboost Feature engineering</a></p><h3 id=\"wnd_drctn-008-score-up\">wnd_drctn (0.08 score up)</h3><p align=\"center\">  <img src=\"/assets/2019/12_01/wind.png\" /></p><ul>  <li>Assuming that the wind direction is different for each season, there is a possibility of fire depending on the direction of the season</li>  <li>Data categorization into 4 types according to wind direction</li>  <li>Apply binning to wind direction (wnd_drctn)</li></ul><h2 id=\"bin_hour--created-feature-003-score-up\">bin_hour : created feature (0.03 score up)</h2><p align=\"center\">  <img src=\"/assets/2019/12_01/fire.png\" /></p><ul>  <li>Assume that it will be difficult to report a fire at dawn.</li>  <li>As a result of the check, according to the statistics of Seoul, there is a difference in the occurrence of fires according to time zones.</li>  <li>Similarly, Gimhae Fire &amp; Marine Insurance determined that there was a difference in the frequency of fire occurrence by time period, and categorized data by time period.</li></ul><h1 id=\"03-data-distribution-control\">03 Data distribution control</h1><hr /><ul>  <li>Check the distribution of Train / Validation / Test data. Control the distribution similarly to the actual test data to be used.</li>  <li>    <p>What is unusual about this competition is that validation data was given. Therefore, it was assumed that at least the validation data would have a similar distribution to the test data, but the difference and correlation between the CV score and the LB score could not be derived, so the work was performed assuming that the distribution would be different.</p>  </li>  <li>Adverserial validation 및 UMAP dimension reduction visualization 으로 확인</li></ul><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_final/etc_experiment/adverserial_validation/#01_adverserial_test_v11.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : Adverserial Validation</a></p><p><a href=\"https://github.com/jaewoo-so/gimhae_fire_prediction/blob/master/code_final/etc_experiment/umap_dimentional_reduction/01_datav04_Apply_umap_test.ipynb\" style=\"color: blue; text-decoration: underline;\">Jupyter notebook : UMAP dimension reduction visualization</a></p><h1 id=\"04-sampling\">04 Sampling</h1><hr /><ul>  <li>The following sampling strategies were used to control for differences in data distribution.</li></ul><h2 id=\"1-a-dimensionally-reduced-low-dimensional-vector-that-samples-only-samples-that-are-close-to-the-test-sample\">1. A dimensionally reduced, low-dimensional vector that samples only samples that are close to the test sample.</h2><p align=\"center\">  <img src=\"/assets/2019/12_01/euclidian.png\" /></p><p>euclidean distance</p><p>The black dot is the test data. Model training proceeds by removing samples that are far from the black point distance and sampling only samples that are close to the black point.The criterion of closeness was experimentally determined.</p><h2 id=\"2-picking-with-predicted-probabilities\">2. Picking with Predicted Probabilities</h2><ul>  <li>Create a train or not, validation or not, test or not classification model and extract train and validation samples that are indistinguishable from test.</li></ul><p align=\"center\">  <img src=\"/assets/2019/12_01/te.png\" /></p><p>Probability distribution of predicted values for test data or not.  <br />Even though it is test data, there are also samples that are not test data. At this time, select training and validation samples that are predicted with a similar probability to the test data. (mainly between 0.05 and 0.15)  <br />Conversely, samples predicted as test data are also selected even though they are not test data. (mainly between 0.8 and 1.0)</p>",
            "url": "http://0.0.0.0:8701/2019/12/01/gimhae-fire-prediction-competition",
            
            
            
            
            
            "date_published": "2019-12-01T00:00:00+09:00",
            "date_modified": "2019-12-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2017/03/01/si-ge-thickness-and-composition-predict-system",
            "title": "Si-Ge Thickness and Composition Predict System[KR]",
            "summary": null,
            "content_text": "개요배경 및 목적데이터측정 방법방법나노 단위의 움직임을 위해서는 진공스테이지와 고정밀모터가 필요.디스커션",
            "content_html": "<h1 id=\"개요\">개요</h1><h1 id=\"배경-및-목적\">배경 및 목적</h1><h1 id=\"데이터\">데이터</h1><h1 id=\"측정-방법\">측정 방법</h1><h1 id=\"방법\">방법</h1><p>나노 단위의 움직임을 위해서는 진공스테이지와 고정밀모터가 필요.</p><h1 id=\"디스커션\">디스커션</h1>",
            "url": "http://0.0.0.0:8701/2017/03/01/si-ge-thickness-and-composition-predict-system",
            
            
            
            
            
            "date_published": "2017-03-01T00:00:00+09:00",
            "date_modified": "2017-03-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "http://0.0.0.0:8701/2015/03/01/swarm-reinforcement-learning-algorithm-with-characterized-agents",
            "title": "Swarm Reinforcement Learning Algorithm with Characterized Agents",
            "summary": null,
            "content_text": "  에이전트 병렬 학습 최적화  model free",
            "content_html": "<ul>  <li>에이전트 병렬 학습 최적화</li>  <li>model free</li></ul><p><img src=\"/assets/2020/01_23/canberra.png\" alt=\"adasdasdasd\" /></p>",
            "url": "http://0.0.0.0:8701/2015/03/01/swarm-reinforcement-learning-algorithm-with-characterized-agents",
            
            
            
            
            
            "date_published": "2015-03-01T00:00:00+09:00",
            "date_modified": "2015-03-01T00:00:00+09:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        }
    
    ]
}